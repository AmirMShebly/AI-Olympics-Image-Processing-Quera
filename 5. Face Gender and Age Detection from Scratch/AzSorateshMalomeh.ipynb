{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed6ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Mount your Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the path to the zip file (update this if needed)\n",
    "zip_file_path = '/content/drive/MyDrive/Face, Age, Gender/data/data.zip'\n",
    "\n",
    "# Define the folder where you want to unzip the file\n",
    "extract_folder = '/content/drive/MyDrive/Face, Age, Gender/data/data'\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(\"Unzipping complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b4a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4884da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv('/content/drive/MyDrive/Face, Gender, Age data/data/data/train.csv')\n",
    "raw_train_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a8a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_path = '/content/drive/MyDrive/Face, Gender, Age data/data/data/train.csv'\n",
    "img_folder = '/content/drive/MyDrive/Face, Gender, Age data/data/data/image_data'\n",
    "\n",
    "\n",
    "def process_images_and_labels(data_path, img_folder, target_size=(128,128)):\n",
    "    raw_train_data = pd.read_csv(data_path)\n",
    "    x_train = []\n",
    "    y_age_train = []\n",
    "    y_gender_train = []\n",
    "\n",
    "    for idx, row in raw_train_data.iterrows():\n",
    "        img_path = os.path.join(img_folder, row['Filename'])\n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize(target_size)\n",
    "\n",
    "            x_train.append(np.array(img)) \n",
    "\n",
    "        if row['Young'] == 1:\n",
    "            y_age_train.append('Young')\n",
    "        elif row['Middle_Aged'] == 1:\n",
    "            y_age_train.append('Middle_Aged')\n",
    "        elif row['Senior'] == 1:\n",
    "            y_age_train.append('Senior')\n",
    "        else:\n",
    "            y_age_train.append('Middle_Aged')\n",
    "\n",
    "        if row['Male'] == 1:\n",
    "            y_gender_train.append('male')\n",
    "        elif row['Male'] == -1:\n",
    "            y_gender_train.append('female')\n",
    "        else :\n",
    "          y_gender_train.append('male')\n",
    "\n",
    "    return np.array(x_train), np.array(y_age_train), np.array(y_gender_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84751e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_age_train, y_gender_train = process_images_and_labels(data_path, img_folder)\n",
    "print(x_train.shape)\n",
    "print(len(y_age_train))\n",
    "print((y_gender_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcefa7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class age_detector(nn.Module):\n",
    "    def __init__(self, image_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 16, kernel_size=4, stride=2),\n",
    "            nn.InstanceNorm2d(16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),#6\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),#6\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, num_classes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9e3a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "age_model = age_detector()\n",
    "optim = Adam(age_model.parameters(), lr=0.002)\n",
    "device = torch.device('cuda')\n",
    "age_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9a120aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_age_train, y_gender_train = process_images_and_labels(data_path, img_folder)\n",
    "print(x_train.shape)\n",
    "print(len(y_age_train))\n",
    "print((y_gender_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3672b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_age_train))\n",
    "print(len(y_gender_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2ba5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8da925f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(y_age_train, y_gender_train):\n",
    "  age_encoder = LabelEncoder()\n",
    "  gender_encoder = LabelEncoder()\n",
    "  y_age_train_encoded = age_encoder.fit_transform(y_age_train)\n",
    "  y_gender_train_encoded = gender_encoder.fit_transform(y_gender_train)\n",
    "\n",
    "  return y_age_train_encoded, y_gender_train_encoded\n",
    "\n",
    "\n",
    "y_age_train , y_gender_train = encode_labels(y_age_train, y_gender_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54428856",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)]\n",
    ")\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa8fd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ageDataset(data.Dataset):\n",
    "  def __init__(self, x_data, y_age, transform=None):\n",
    "    self.x_data = x_data\n",
    "    self.y_age = y_age\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    image = Image.fromarray(self.x_data[index])\n",
    "    age_label = self.y_age[index]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image, torch.tensor(age_label, dtype=torch.long)\n",
    "train_age_dataset = ageDataset(x_train, y_age_train,  transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c2af2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_age = data.DataLoader(train_age_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dc4e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "496763ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for images, labels in tqdm(train_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  return running_loss / len(train_loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3500763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss, train_acc = train(age_model, train_loader_age, optim, criterion, device)\n",
    "  print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%')\n",
    "  print(epoch+1)\n",
    "torch.save(age_model.state_dict(), \"age_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b4bea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_age_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b35def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_age_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70ff0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_age_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffe29992",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_age_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8bbe27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gender_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d6a00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gender_train[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b21ec342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gender_train[:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8e082c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gender_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f09fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gender_train[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f6a38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gender_train[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67425401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sexDataset(data.Dataset):\n",
    "  def __init__(self, x_data, y_gender, transform=None):\n",
    "    self.x_data = x_data\n",
    "    self.y_sex = y_gender\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    image = Image.fromarray(self.x_data[index])\n",
    "    sex_label = self.y_sex[index]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image, torch.tensor(sex_label, dtype=torch.long)\n",
    "train_sex_dataset = sexDataset(x_train, y_gender_train,  transform=train_transform)\n",
    "train_loader_sex = data.DataLoader(train_sex_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b062aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class sex_detector(nn.Module):\n",
    "    def __init__(self, image_channels=3, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 16, kernel_size=4, stride=2),\n",
    "            nn.InstanceNorm2d(16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),#6\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),#6\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(16, num_classes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8b3ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "sex_model = sex_detector()\n",
    "optim2 = Adam(sex_model.parameters(), lr=0.002)\n",
    "device = torch.device('cuda')\n",
    "sex_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac55770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for images, labels in tqdm(train_loader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  return running_loss / len(train_loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdceebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  train_loss, train_acc = train(sex_model, train_loader_sex, optim2, criterion2, device)\n",
    "\n",
    "  print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%')\n",
    "  print(f'sex :{epoch+1}')\n",
    "\n",
    "\n",
    "torch.save(sex_model.state_dict(), \"sex_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b3ff9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/content/drive/MyDrive/Face, Age, Gender/data/data/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bbcb9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_path = '/content/drive/MyDrive/Face, Gender, Age data/data/data/test.csv'\n",
    "img_folder = '/content/drive/MyDrive/Face, Gender, Age data/data/data/image_data'\n",
    "\n",
    "\n",
    "def test_process_images_and_labels(data_path, img_folder, target_size=(128,128)):\n",
    "    raw_train_data = pd.read_csv(data_path)\n",
    "    x_test = []\n",
    "    y_age_test = []\n",
    "    y_gender_test = []\n",
    "\n",
    "    for idx, row in raw_train_data.iterrows():\n",
    "        img_path = os.path.join(img_folder, row['Filename'])\n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize(target_size)\n",
    "\n",
    "            x_test.append(np.array(img))\n",
    "\n",
    "    return np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54684200",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_process_images_and_labels(data_path, img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "416c6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_predictions = []\n",
    "age_predictions = []\n",
    "\n",
    "sex_model.eval().to(device)\n",
    "age_model.eval().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images in test_data_loader:\n",
    "    images = images.to(device)\n",
    "\n",
    "    gender_outputs = sex_model(images)\n",
    "    age_outputs = age_model(images)\n",
    "\n",
    "    gender_pred = torch.argmax(gender_outputs, dim=1).cpu().numpy()\n",
    "    age_pred = torch.argmax(age_outputs, dim=1).cpu.numpy()\n",
    "\n",
    "    gender_predictions.extend(gender_pred)\n",
    "    age_predictions.extend(age_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96d974a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_process_images_and_labels(data_path, img_folder)\n",
    "test_loader = data.DataLoader(x_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1d7e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(data.Dataset):\n",
    "  def __init__(self, x_data, transform=None):\n",
    "    self.x_data = x_data\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    image = Image.fromarray(self.x_data[index])\n",
    "    age_label = self.y_age[index]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    return image\n",
    "test_dataset = testDataset(x_test,  transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a3ffb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97a1d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_predictions = []\n",
    "age_predictions = []\n",
    "\n",
    "sex_model.eval().to(device)\n",
    "age_model.eval().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images in test_loader:\n",
    "    images = images.to(device).float() \n",
    "\n",
    "    gender_outputs = sex_model(images)\n",
    "    age_outputs = age_model(images)\n",
    "\n",
    "    gender_pred = torch.argmax(gender_outputs, dim=1).cpu().numpy()\n",
    "    age_pred = torch.argmax(age_outputs, dim=1).cpu.numpy()\n",
    "\n",
    "    gender_predictions.extend(gender_pred)\n",
    "    age_predictions.extend(age_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29dbf587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(data.Dataset):\n",
    "    def __init__(self, x_data, transform=None):\n",
    "        self.x_data = x_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.fromarray(self.x_data[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image \n",
    "\n",
    "test_dataset = testDataset(x_test,  transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1cd80fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "500b9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_predictions = []\n",
    "age_predictions = []\n",
    "\n",
    "sex_model.eval().to(device)\n",
    "age_model.eval().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images in test_loader:\n",
    "    images = images.to(device).float() \n",
    "\n",
    "    gender_outputs = sex_model(images)\n",
    "    age_outputs = age_model(images)\n",
    "\n",
    "    gender_pred = torch.argmax(gender_outputs, dim=1).cpu().numpy()\n",
    "    age_pred = torch.argmax(age_outputs, dim=1).cpu.numpy()\n",
    "\n",
    "    gender_predictions.extend(gender_pred)\n",
    "    age_predictions.extend(age_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4f9c7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_predictions = []\n",
    "age_predictions = []\n",
    "\n",
    "sex_model.eval().to(device)\n",
    "age_model.eval().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images in test_loader:\n",
    "    images = images.to(device).float() \n",
    "\n",
    "    gender_outputs = sex_model(images)\n",
    "    age_outputs = age_model(images)\n",
    "\n",
    "    gender_pred = torch.argmax(gender_outputs, dim=1).cpu().numpy()\n",
    "    age_pred = torch.argmax(age_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "    gender_predictions.extend(gender_pred)\n",
    "    age_predictions.extend(age_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1fad658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "male_column = []\n",
    "young_column = []\n",
    "middle_aged_column = []\n",
    "senior_column = []\n",
    "\n",
    "for gender_pred, age_pred in zip(gender_predictions, age_predictions):\n",
    "\n",
    "    male_column.append(1 if gender_pred == 1 else -1)\n",
    "\n",
    "    if age_pred == 0:\n",
    "        young_column.append(-1)\n",
    "        middle_aged_column.append(1)\n",
    "        senior_column.append(-1)\n",
    "    elif age_pred == 1:\n",
    "        young_column.append(-1)\n",
    "        middle_aged_column.append(-1)\n",
    "        senior_column.append(1)\n",
    "    elif age_pred == 2:\n",
    "        young_column.append(1)\n",
    "        middle_aged_column.append(-1)\n",
    "        senior_column.append(-1)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Male': male_column,\n",
    "    'Young': young_column,\n",
    "    'Middle_Aged': middle_aged_column,\n",
    "    'Senior': senior_column\n",
    "})\n",
    "\n",
    "submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
